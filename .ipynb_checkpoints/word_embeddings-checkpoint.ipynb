{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8d1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "#relative path to datasets \"./datasets/\"\n",
    "\n",
    "# load model\n",
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cd02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_vec = nlp(\"Licht\").vector\n",
    "two_vec = nlp(\"BÃ¼cherregal\").vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d6253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine distance between the word embeddings for word 1 and word 2 is: 0.6893520057201385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"The cosine distance between the word embeddings for word 1 and word 2 is: {cosine(one_vec, two_vec)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b08470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.0752  , -0.052088,  0.60382 ,  0.23162 , -0.21381 ,  1.4621  ,\n",
       "       -0.32145 , -0.071567, -3.733   ,  1.1004  , -2.6463  ,  1.1514  ,\n",
       "       -3.451   , -0.95073 , -4.7936  , -3.1064  , -3.5796  , -2.1671  ,\n",
       "       -1.2613  ,  5.7152  , -2.4114  ,  2.0229  , -1.9983  ,  1.4919  ,\n",
       "        4.9169  , -2.3062  ,  6.8677  , -2.819   , -1.9696  , -1.1616  ,\n",
       "       -4.3073  ,  2.9533  ,  1.2956  , -0.85872 ,  4.7655  , -3.601   ,\n",
       "        0.72205 ,  3.877   , -1.801   ,  0.98335 ,  4.1955  , -5.1654  ,\n",
       "       -0.20053 ,  0.41995 , -0.26976 , -1.5451  , -3.257   ,  3.8955  ,\n",
       "        2.0029  ,  6.0553  ,  0.57748 , -4.8316  ,  5.5656  ,  0.82004 ,\n",
       "       -4.1175  ,  0.37747 ,  3.1744  , -0.52983 ,  2.98    ,  0.98243 ,\n",
       "        4.3077  , -3.2109  , -1.2541  ,  3.785   ,  0.22053 ,  5.6301  ,\n",
       "       -1.0759  , -2.5483  ,  0.59063 , -1.5122  , -3.4592  ,  4.1474  ,\n",
       "        0.88603 , -2.0307  ,  5.8646  , -0.45411 ,  4.1962  , -1.4863  ,\n",
       "       -1.2105  ,  4.0127  , -2.1485  , -1.2526  , -3.9192  ,  2.0151  ,\n",
       "       -2.5673  ,  4.215   ,  4.3686  ,  0.3871  , -3.633   , -6.9916  ,\n",
       "        1.796   , -0.36455 , -0.99022 ,  1.1335  , -2.1241  ,  1.6709  ,\n",
       "        1.9984  , -2.4769  , -3.9118  ,  1.477   , -0.16424 ,  1.9945  ,\n",
       "        5.5158  , -3.5534  ,  0.1636  ,  0.5751  , -4.0234  ,  7.1463  ,\n",
       "       -2.0863  , -0.09572 , -2.9192  , -0.79613 ,  1.5328  ,  5.781   ,\n",
       "       -1.5654  , -1.0806  ,  4.806   , -1.1525  , -2.0597  , -1.2751  ,\n",
       "        8.6031  , -3.7093  , -8.0699  , -0.25009 ,  3.2837  , -0.23158 ,\n",
       "       -1.0474  ,  2.8821  , -3.0775  , -0.51633 ,  1.2735  ,  2.4288  ,\n",
       "       -1.7381  ,  0.79422 , -2.7924  ,  0.83123 ,  4.8501  ,  1.8004  ,\n",
       "       -0.46928 ,  3.648   , -2.302   , -0.12244 ,  4.1231  ,  1.3245  ,\n",
       "       -1.9624  ,  4.0211  ,  3.2959  , -1.2839  , -0.17772 , -1.1206  ,\n",
       "       -2.7793  ,  3.7729  ,  0.15706 , -1.0598  , -1.0828  , -1.6112  ,\n",
       "        1.8102  ,  1.6109  , -8.3481  ,  1.5012  ,  3.3544  , -1.547   ,\n",
       "       -3.0383  ,  0.2901  ,  0.65154 ,  2.8218  , -1.4625  ,  3.0616  ,\n",
       "        2.938   , -1.1202  ,  5.4044  , -1.6719  ,  1.5693  ,  5.6748  ,\n",
       "        1.6394  ,  5.0325  ,  3.1228  ,  2.9006  ,  3.0404  ,  4.8131  ,\n",
       "        0.40711 , -1.7458  , -1.692   , -2.818   , -0.15243 , -4.319   ,\n",
       "        1.2679  , -0.31513 ,  0.063245,  2.0299  , -9.9638  , -0.51986 ,\n",
       "        4.4149  , -0.72103 , -3.7483  , -1.8571  , -5.5253  ,  1.8538  ,\n",
       "        0.98361 ,  4.2202  , -0.62636 , -0.042714,  0.2713  ,  4.5344  ,\n",
       "       -1.9293  ,  3.5316  , -3.5274  ,  4.5976  ,  4.3808  ,  5.5416  ,\n",
       "       -0.2888  ,  0.32804 , -1.6048  , -3.5523  ,  4.1694  ,  0.098702,\n",
       "        3.8741  , -5.5395  ,  0.62091 ,  1.1917  , -0.10165 , -1.8824  ,\n",
       "       -4.2363  , -2.2889  , -1.013   , -4.2355  ,  0.12783 ,  2.5709  ,\n",
       "        3.0021  , -3.0711  , -5.9405  ,  0.90729 ,  3.0811  , -0.71681 ,\n",
       "        1.7418  ,  4.0884  , -0.38993 ,  5.4469  , -4.4685  , -2.0474  ,\n",
       "       -0.53099 , -0.6333  , -1.9296  , -0.63051 ,  5.5961  ,  2.6533  ,\n",
       "        5.6133  ,  1.8134  , -2.9221  , -5.2649  , -1.0938  , -0.22891 ,\n",
       "       -2.3486  , -1.4575  , -2.6154  , -0.18995 , -0.16809 ,  1.2739  ,\n",
       "       -0.19067 ,  0.65576 , -2.0057  , -5.6202  ,  1.8492  ,  1.2934  ,\n",
       "       -5.2779  ,  1.1626  , -0.24342 ,  4.1913  ,  0.70819 , -1.2412  ,\n",
       "       -1.0037  , -0.35459 ,  6.063   , -2.9429  , -2.0796  , -1.5301  ,\n",
       "       -2.6724  , -1.0815  , -4.5578  , -3.5105  ,  2.9694  ,  2.9901  ,\n",
       "       -4.0302  , -1.9402  , -0.23049 , -2.741   , -1.7973  , -0.28    ,\n",
       "        2.0209  ,  2.899   ,  2.7484  , -0.011971, -2.6205  , -4.462   ,\n",
       "       -3.87    , -3.2096  , -0.52547 ,  1.5248  ,  5.4314  ,  1.6606  ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.41373  ,  1.6625   , -0.77732  ,  0.69637  , -2.9069   ,\n",
       "       -0.19694  ,  1.9318   , -0.84845  , -2.3321   , -0.22592  ,\n",
       "        2.7451   ,  0.06969  ,  0.91666  ,  0.88641  ,  0.5318   ,\n",
       "       -1.0371   , -1.078    ,  0.57417  , -0.88194  ,  1.4894   ,\n",
       "       -0.91271  ,  0.37811  , -2.2066   ,  1.2407   ,  0.96132  ,\n",
       "       -0.043267 ,  0.81249  , -1.5054   ,  0.86728  , -0.57307  ,\n",
       "       -0.024234 ,  0.61774  ,  0.59266  ,  1.6046   ,  2.2076   ,\n",
       "        1.3147   , -1.0158   , -0.16646  ,  0.95626  ,  1.311    ,\n",
       "       -0.43556  , -0.90588  , -3.0829   , -0.97211  , -0.5881   ,\n",
       "        1.0213   , -0.12051  , -0.029154 , -0.085361 ,  0.14649  ,\n",
       "        0.70696  , -3.3059   ,  0.12865  ,  2.7252   ,  2.1968   ,\n",
       "        1.2756   ,  0.71825  , -0.45248  ,  0.69113  , -0.60343  ,\n",
       "       -0.78768  , -0.66228  ,  1.7868   , -0.40243  ,  0.17927  ,\n",
       "        1.2431   ,  2.2438   ,  1.207    ,  1.3209   ,  1.1751   ,\n",
       "        0.29315  ,  0.64789  , -0.88663  ,  3.8045   ,  1.3066   ,\n",
       "        1.5587   ,  0.95465  , -0.062049 , -0.36135  ,  1.4276   ,\n",
       "       -0.82548  ,  0.5449   , -1.3711   ,  0.66112  , -2.6819   ,\n",
       "        2.3821   ,  2.0537   ,  0.84909  , -0.64003  , -0.22932  ,\n",
       "       -1.887    , -1.3697   , -1.813    , -1.4406   ,  1.0872   ,\n",
       "        0.58532  ,  0.11256  , -1.3251   ,  0.74375  ,  2.0247   ,\n",
       "        0.55977  , -1.1467   ,  3.6346   ,  0.018737 , -1.4407   ,\n",
       "        0.49181  , -0.73212  ,  1.9783   , -0.66345  ,  2.0655   ,\n",
       "       -0.31934  ,  1.9948   ,  0.37618  ,  0.17981  , -0.51278  ,\n",
       "       -0.17637  , -1.5857   , -0.69783  ,  1.408    , -0.31149  ,\n",
       "        1.9858   , -1.7881   , -0.28144  , -1.9122   , -0.92365  ,\n",
       "       -0.27271  , -1.1709   ,  2.1435   , -0.22531  , -1.3073   ,\n",
       "       -1.3043   , -0.050958 , -0.29686  ,  1.4126   ,  0.33543  ,\n",
       "        0.64029  , -0.46614  ,  1.7824   ,  0.61949  , -0.51233  ,\n",
       "        0.82515  , -1.2246   ,  1.2261   ,  2.2325   , -2.2916   ,\n",
       "       -0.48129  ,  1.5271   ,  0.8044   ,  0.42146  , -0.21465  ,\n",
       "       -0.69116  ,  0.573    ,  0.0069276,  0.98195  , -0.94543  ,\n",
       "       -1.1252   , -1.1675   ,  2.021    , -1.4074   ,  0.25052  ,\n",
       "        2.0226   ,  1.2639   , -1.5926   ,  0.7184   ,  1.3906   ,\n",
       "        3.4504   , -0.64047  ,  0.97423  ,  1.4157   ,  0.64854  ,\n",
       "       -2.6042   ,  0.28112  , -0.94646  ,  0.81503  ,  2.1015   ,\n",
       "        0.76893  ,  0.61079  ,  1.8676   , -3.035    ,  1.7584   ,\n",
       "        0.41597  ,  2.7771   , -3.0254   ,  0.63121  , -0.5889   ,\n",
       "       -2.0097   , -0.72173  , -1.9085   , -2.6872   ,  1.0095   ,\n",
       "       -2.6837   , -1.2061   ,  2.8212   ,  0.48486  ,  1.023    ,\n",
       "       -0.35012  , -1.5406   , -0.86003  ,  2.3905   ,  0.064525 ,\n",
       "       -1.294    , -0.27201  ,  0.53907  ,  0.70903  ,  1.0345   ,\n",
       "        3.4323   ,  0.2042   ,  1.3725   ,  2.4502   ,  1.6728   ,\n",
       "       -0.39829  ,  0.63078  , -2.6145   , -0.26756  ,  0.14309  ,\n",
       "       -0.19084  , -0.92659  , -0.39982  , -2.0403   , -1.988    ,\n",
       "        1.5419   ,  0.45268  , -0.2151   ,  0.14601  , -1.9114   ,\n",
       "       -0.48026  , -0.75924  , -0.23019  ,  2.7501   , -3.2229   ,\n",
       "       -1.0045   , -0.70794  ,  0.96481  , -1.5062   , -1.6801   ,\n",
       "        0.20609  ,  1.2086   ,  0.90232  , -1.3774   , -1.3986   ,\n",
       "       -0.11315  , -0.32526  ,  0.6429   ,  2.2748   ,  1.2879   ,\n",
       "       -2.4726   , -1.0424   , -0.14253  ,  0.42293  , -0.40137  ,\n",
       "        1.8149   ,  0.31862  ,  0.0059273,  0.63925  ,  1.6171   ,\n",
       "       -0.67565  ,  1.6241   , -2.8129   ,  0.96918  , -2.5118   ,\n",
       "        1.4782   , -0.46289  , -0.026037 , -1.2678   , -1.2018   ,\n",
       "       -0.030794 , -0.35021  ,  1.0811   ,  2.2019   ,  2.6041   ,\n",
       "        0.20003  ,  1.9244   ,  0.3626   , -0.15724  ,  0.94145  ,\n",
       "        0.050261 ,  1.9108   , -1.114    , -1.7434   , -1.3936   ,\n",
       "        1.1711   ,  0.60406  , -0.93557  , -0.766    , -1.1658   ,\n",
       "       -1.1256   ,  0.98353  ,  0.61284  , -0.78664  ,  2.6033   ,\n",
       "       -0.34208  , -1.0916   , -4.7184   , -2.7538   ,  1.2202   ,\n",
       "       -0.39056  ,  0.85202  ,  1.7242   ,  1.0333   ,  0.2357   ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LÃ¤nge des ersten Vektors: 300'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'LÃ¤nge des zweiten Vektors: 300'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(one_vec)\n",
    "display(two_vec)\n",
    "display(f\"LÃ¤nge des ersten Vektors: {len(one_vec)}\")\n",
    "display(f\"LÃ¤nge des zweiten Vektors: {len(two_vec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9f7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HanTa import HanoverTagger as ht\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf8934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "stopwords_custom = ['echt', 'richtig', 'tun', 'verdammt', 'lang', 'vielen', 'bei', 'beim', 'dabei', 'ja', 'nein', 'finden', 'lassen', 'andere', 'der', 'weil', 'wieder', 'gar', 'gut', 'kommen', 'zwar', 'super', 'top', 'topp', 'toll', 'kennen', 'machen', 'leider', 'nicht', 'wirklich', 'absolut', 'immer', 'nie', 'mehr', 'schon', 'total', 'ganz', 'einfach', 'sehr', 'oder', 'viel', 'viele', 'letzte', 'letzter', 'letztes', 'so', 'solcher', 'unseres', 'doch', 'ihren', 'vor', 'ihm', 'hatte', 'muss', 'selbst', 'eurer', 'welchen', 'meine', 'was', 'werden', 'kann', 'einem', 'jedes', 'ihr', 'sie', 'sind', 'diesem', 'zu', 'jener', 'unser', 'sollte', 'manches', 'zur', 'diesen', 'allem', 'unserem', 'anderen', 'dieses', 'einen', 'hatten', 'einigem', 'hat', 'zwischen', 'zum', 'welche', 'dieser', 'nach', 'wÃ¤hrend', 'wollte', 'bei', 'ich', 'dann', 'ihre', 'solchem', 'warst', 'das', 'meinen', 'sich', 'eure', 'einigen', 'deiner', 'keiner', 'da', 'meinem', 'kÃ¶nnte', 'seinen', 'dort', 'mein', 'wird', 'uns', 'am', 'derer', 'seine', 'er', 'daÃ', 'deines', 'wÃ¼rden', 'um', 'keines', 'musste', 'unsere', 'haben', 'weg', 'wo', 'wollen', 'dich', 'unter', 'in', 'ins', 'jeder', 'hier', 'von', 'dieselbe', 'dir', 'denn', 'diese', 'hab', 'indem', 'mit', 'einmal', 'allen', 'den', 'machen', 'ander', 'damit', 'durch', 'im', 'mich', 'dasselbe', 'euer', 'deinem', 'jenem', 'derselbe', 'dessen', 'alle', 'gewesen', 'aus', 'soll', 'jenen', 'welchem', 'anders', 'bin', 'bis', 'jene', 'solchen', 'du', 'ihres', 'demselben', 'als', 'will', 'wirst', 'war', 'jede', 'eures', 'dieselben', 'jedem', 'einige', 'eine', 'einiger', 'manche', 'seines', 'sein', 'denselben', 'noch', 'welcher', 'nur', 'mal', 'viel', 'ein', 'meiner', 'mancher', 'ihrer', 'desselben', 'ihrem', 'meines', 'dies', 'einer', 'jetzt', 'auch', 'fÃ¼r', 'wenn', 'solches', 'Ã¼ber', 'welches', 'ist', 'wie', 'es', 'anderm', 'deine', 'habe', 'wir', 'ohne', 'hin', 'dem', 'einiges', 'manchem', 'und', 'vom', 'wÃ¼rde', 'manchen', 'euch', 'solche', 'jenes', 'euren', 'aller', 'ihnen', 'eines', 'hinter', 'seinem', 'etwas', 'aber', 'kein', 'mir', 'dass', 'sondern', 'andern', 'anderes', 'unseren', 'dein', 'seiner', 'nun', 'jeden', 'anderer', 'man', 'weiter', 'sonst', 'keinem', 'alles', 'gegen', 'werde', 'bist', 'an', 'einig', 'ihn', 'auf', 'keine', 'des', 'eurem', 'derselben', 'anderem', 'dazu', 'kÃ¶nnen', 'waren', 'deinen', 'keinen', 'also', 'ob', 'die', 'une', 'retenter', 'gr', 'grad', 'tastes', 'texture', 'de', 'weekly', 'vÃ©gÃ©tal', 'break', 'bang', 'par', 'wheaty', 'pan', 'that', 'mai', 'hungry', 'additionally', 'after', 'cuisson', 'palette', 've', 'veau', 'vater', 'doutes', 'buns', 'ein', 'per', 'charcuteries', 'grad', 'haut', 'big', 'celle', 'certainement', 'contre', 'convincing', 'maie']\n",
    "\n",
    "def clean_text(words):\n",
    "    re_ascii = re.compile(r\"[^A-Za-zÃ-Å¾ ]\", re.IGNORECASE)\n",
    "    words = re.sub(re_ascii, \" \", words)\n",
    "    tokenized = word_tokenize(words)\n",
    "    text_lower = [token.lower() for token in tokenized]\n",
    "    stopwords_removed = [word for word in text_lower if word not in stopwords_custom]\n",
    "    lemmatized = [tagger.analyze(word)[0].lower() for word in stopwords_removed]\n",
    "    stopwords_again = [word for word in lemmatized if word not in stopwords_custom]\n",
    "    filtered = \" \".join(stopwords_again)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d432045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zuckergehalt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GehÃ¶ren in jeden veganen Haushalt!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schon ein Klassiker...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Geschmack ist pappig und maggiartig, die Konsi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>Da scheiden sich sie Geister. So meiner ist er...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>Richtig lecker, aber leider zu trocken. Da geh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>Die Muffins haben zwar eine guten Preis, waren...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>Die helle Muffin Variante mit SchokostÃ¼cken vo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8004 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  positive\n",
       "0                                          Zuckergehalt         1\n",
       "1                    GehÃ¶ren in jeden veganen Haushalt!         1\n",
       "2                                Schon ein Klassiker...         1\n",
       "3                                                Super!         1\n",
       "4                                                Super!         1\n",
       "...                                                 ...       ...\n",
       "7999  Geschmack ist pappig und maggiartig, die Konsi...         0\n",
       "8000  Da scheiden sich sie Geister. So meiner ist er...         0\n",
       "8001  Richtig lecker, aber leider zu trocken. Da geh...         0\n",
       "8002  Die Muffins haben zwar eine guten Preis, waren...         0\n",
       "8003  Die helle Muffin Variante mit SchokostÃ¼cken vo...         0\n",
       "\n",
       "[8004 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = pd.read_csv(\"./datasets/clean_review_data.csv\")\n",
    "review_data[\"text\"] = review_data[\"text\"].astype(str)\n",
    "review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8ed4ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = review_data.assign(clean_comments = review_data[\"text\"].apply(lambda row: clean_text(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ac1c4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_of_comments = review_data[\"clean_comments\"].tolist()\n",
    "lst_of_lst_of_comments = [sentence.split() for sentence in lst_of_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba4ee99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "682b1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(lst_of_lst_of_comments, min_count = 1, vector_size = 200, workers = 3, window = 5, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0d143fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leben', 0.9984369874000549),\n",
       " ('kÃ¼che', 0.9982132315635681),\n",
       " ('zeit', 0.9982126355171204),\n",
       " ('ernÃ¤hren', 0.9981766939163208),\n",
       " ('zufrieden', 0.9981326460838318),\n",
       " ('glutenfrei', 0.9981077909469604),\n",
       " ('vegetarier', 0.99808269739151),\n",
       " ('verwenden', 0.9980669617652893),\n",
       " ('grund', 0.998064398765564),\n",
       " ('qualitÃ¤t', 0.9980459809303284)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_vegan = model.wv.most_similar(\"vegan\", topn=10)\n",
    "similar_vegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5482323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "\n",
    "#Bevor Topic Modeling fortgesetzt wird:\n",
    "#Modeling von kurzen, Ã¤hnlichen Rezensionen macht wenig Sinn.\n",
    "#Ideen:\n",
    "# - Rezensionen nach gut und schlecht vorsortieren\n",
    "# - nur ausfÃ¼hrliche Rezensionen modellieren (s. Ende des Datensatzes)\n",
    "# - n-grams\n",
    "# - Datensatz aus Veganer-Forum verwenden"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
